{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune the pre-trained FaceNet model towards the Caltech Face Dataset (450 images, 30 peaple) using triplet loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang.zhai\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "Using Theano backend.\n",
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "C:\\Users\\xiang.zhai\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\theano\\configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.configdefaults): install mkl with `conda install mkl-service`: No module named 'mkl'\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import imp\n",
    "import numpy as np\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#import tensorflow as tf\n",
    "#import theano\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def set_keras_backend(backend):\n",
    "\n",
    "    if K.backend() != backend:\n",
    "        os.environ['KERAS_BACKEND'] = backend\n",
    "        imp.reload(K)\n",
    "        assert K.backend() == backend\n",
    "\n",
    "set_keras_backend(\"theano\")\n",
    "\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Lambda\n",
    "from keras.layers import Input, Subtract, add, Dot\n",
    "from keras import optimizers\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.FaceNet_utils import one_hot, distance_based_prediction, evaluate_model, face_dist, load_FaceData, load_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFace = 450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "\n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "\n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "\n",
    "#     anchorpositive, anchornegative = y_pred[0], y_pred[1]\n",
    "\n",
    "#     ### START CODE HERE ### (â‰ˆ 4 lines)\n",
    "#     # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
    "#     pos_dist = K.sum(K.square(anchorpositive),axis=-1)\n",
    "#     # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
    "#     neg_dist = K.sum(K.square(anchornegative),axis=-1)\n",
    "#     # Step 3: subtract the two previous distances and add alpha.\n",
    "#     basic_loss = pos_dist - neg_dist + alpha\n",
    "#     # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "#     loss = K.sum(K.maximum(basic_loss,0.0))\n",
    "#     ### END CODE HERE ###\n",
    "\n",
    "    loss = K.sum(K.maximum(y_pred+alpha,0.0))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VecDist(tensors):\n",
    "    dist = K.sum(K.square(tensors[0]-tensors[1]),axis=-1)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Siamese_model(basemodel,alpha = 0.2):\n",
    "    basemodel_input_shape = basemodel.layers[0].input.get_shape().as_list()[1:]\n",
    "    Anchor_Input    = Input(basemodel_input_shape)\n",
    "    Positive_Input  = Input(basemodel_input_shape)\n",
    "    Negative_Input  = Input(basemodel_input_shape)\n",
    "    \n",
    "    Anchor_Predict   = basemodel(Anchor_Input)\n",
    "    Positive_Predict = basemodel(Positive_Input)\n",
    "    Negative_Predict = basemodel(Negative_Input)\n",
    "\n",
    "    AP_dist = Lambda(VecDist, output_shape=(1,))([Anchor_Predict,Positive_Predict])\n",
    "    AN_dist = Lambda(VecDist, output_shape=(1,))([Anchor_Predict,Negative_Predict])\n",
    "\n",
    "    print(AP_dist,AN_dist)\n",
    "    APN = Subtract()([AP_dist,AN_dist])\n",
    "    print(APN)\n",
    "                     \n",
    "    SiameseModel = Model(inputs = [Anchor_Input, Positive_Input, Negative_Input], outputs = APN)\n",
    "    \n",
    "    return SiameseModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n",
      "reset epsilon from 1e-05 to 1e-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang.zhai\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\keras\\layers\\core.py:642: UserWarning: `output_shape` argument not specified for layer lambda_2 and cannot be automatically inferred with the Theano backend. Defaulting to output shape `(None, 128)` (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument.\n",
      "  .format(self.name, input_shape))\n"
     ]
    }
   ],
   "source": [
    "FNModel = load_base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3743280"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FNModel.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450, 3, 96, 96)\n",
      "(450,)\n",
      "(450, 31)\n"
     ]
    }
   ],
   "source": [
    "FaceData, labels, labels_OH = load_FaceData()\n",
    "print(FaceData.shape)\n",
    "print(labels.shape)\n",
    "print(labels_OH.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nPeople = labels_OH.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xiang.zhai\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\theano\\tensor\\nnet\\conv.py:98: UserWarning: theano.tensor.nnet.conv.conv2d is deprecated. Use theano.tensor.nnet.conv2d instead.\n",
      "  warnings.warn(\"theano.tensor.nnet.conv.conv2d is deprecated.\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1835\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1328\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1330\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1331\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1332\u001b[0m                     \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\keras\\backend\\theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1227\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\theano\\compile\\function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, output_subset)\u001b[0m\n\u001b[0;32m    487\u001b[0m                     \u001b[1;31m# -- Non-lazy case: have inputs, time to compute outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_thunk_of_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_apply\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m                         \u001b[1;32mdel\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_global_stats\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\theano\\gof\\vm.py\u001b[0m in \u001b[0;36mrun_thunk_of_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    389\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m         \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_executed_order\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n, params)\u001b[0m\n\u001b[0;32m    899\u001b[0m             def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0;32m    900\u001b[0m                      params=params_val):\n\u001b[1;32m--> 901\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\theano\\tensor\\signal\\pool.py\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inp, out, params)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpool_out_shp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m                 zzk[r] = func(\n\u001b[1;32m--> 574\u001b[1;33m                     yk[[region_slices[i][r[i]] for i in xrange(nd)]])\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minfer_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[1;32m-> 2320\u001b[1;33m                           out=out, **kwargs)\n\u001b[0m\u001b[0;32m   2321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\ML\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# small reductions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%time FaceEmbedding = FNModel.predict(FaceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components = 2)\n",
    "x_std = StandardScaler().fit_transform(FaceEmbedding)\n",
    "x_feature_pca = pca.fit_transform(x_std)\n",
    "plt.scatter(x_feature_pca[:,0],x_feature_pca[:,1],c=labels)\n",
    "plt.title('feature space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FaceEmbedding_Corr = np.corrcoef(FaceEmbedding)\n",
    "plt.imshow(FaceEmbedding_Corr,cmap='jet')\n",
    "plt.title('Correlation matrix')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distances_within_class = []\n",
    "Distances_among_class = []\n",
    "\n",
    "FaceEmbedding_Dist = np.ones((nFace,nFace))*100\n",
    "for i in range(nFace):\n",
    "    for j in range(i,nFace):\n",
    "        FaceEmbedding_Dist[i,j]=face_dist(FaceEmbedding[i,:],FaceEmbedding[j,:])\n",
    "        FaceEmbedding_Dist[j,i]=FaceEmbedding_Dist[i,j]\n",
    "        if labels[i]==labels[j]:\n",
    "            Distances_within_class.append(FaceEmbedding_Dist[i,j])\n",
    "        else:\n",
    "            Distances_among_class.append(FaceEmbedding_Dist[i,j])\n",
    "            \n",
    "Distances_within_class = np.array(Distances_within_class)\n",
    "Distances_among_class = np.array(Distances_among_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(FaceEmbedding_Dist,cmap='jet')\n",
    "plt.title('Distance matrix')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.hist(Distances_among_class,bins = 50, label = 'cross class',normed = True)\n",
    "_ = plt.hist(Distances_within_class,bins = 50, label = 'same class', normed = True)\n",
    "plt.title('Distribution of cross-class distance')\n",
    "plt.legend()\n",
    "\n",
    "print('Cross-class distance = %1.3f +\\- %1.3f' % (Distances_among_class.mean(), Distances_among_class.std()))\n",
    "print('Same-class distance = %1.3f +\\- %1.3f' % (Distances_within_class.mean(), Distances_within_class.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Even before doing anything, the direct embedding of faces using FaceNet is already able to recognize faces at decent level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = []\n",
    "FN = []\n",
    "\n",
    "for threshold in np.arange(0,max(Distances_among_class),0.01):\n",
    "    FP.append(100.0*np.sum(Distances_among_class<threshold)/len(Distances_among_class))\n",
    "    FN.append(100.0*np.sum(Distances_within_class>threshold)/len(Distances_within_class))\n",
    "    \n",
    "plt.plot(FP,FN)  \n",
    "threshold = 0.68\n",
    "print('pct of false positive %2.3f %%' % (100.0*np.sum(Distances_among_class<threshold)/len(Distances_among_class)))\n",
    "print('pct of false negative %2.3f %%' % (100.0*np.sum(Distances_within_class>threshold)/len(Distances_within_class)))\n",
    "\n",
    "print('accuracy = %2.3f' % (100.0*(np.sum(Distances_among_class>threshold)+np.sum(Distances_within_class<threshold))/(len(Distances_among_class)+len(Distances_within_class))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = []\n",
    "test_idx = []\n",
    "for l in set(labels):\n",
    "    ind = np.where(labels==l)[0]\n",
    "    if len(ind)<=1:\n",
    "        ind_train = list(ind)\n",
    "        ind_test = []\n",
    "    else:\n",
    "        i_split = max([3,int(len(ind)*0.7)])\n",
    "        ind_train = list(ind[0:i_split])\n",
    "        ind_test = list(ind[i_split:])\n",
    "    train_idx += ind_train\n",
    "    test_idx += ind_test  \n",
    "print(\"Training data set has %d face images\", len(train_idx))\n",
    "print(\"Test data set has %d face images\", len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCorrect = 0\n",
    "for i in test_idx:\n",
    "    p = distance_based_prediction(FaceEmbedding[train_idx], labels[train_idx], FaceEmbedding[i])\n",
    "    if p == labels[i]:\n",
    "        nCorrect += 1\n",
    "print('Face recognition accuracy using purely distance based method: %3.3f %%' % (100.*(0.+nCorrect)/len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nCorrect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Anchor, positive and negative combinations to train Siamese model built on top of the FaceNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseModel = Create_Siamese_model(FNModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseModel.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseModel.compile(optimizer = 'adam', loss = triplet_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find hard to train positive and negative combinations\n",
    "A = []\n",
    "P = []\n",
    "N = []\n",
    "\n",
    "dist_threshold = 0.4\n",
    "for i in range(nPeople):\n",
    "    ifaces = np.where(labels==i)[0]\n",
    "\n",
    "    iOtherPerson = list(set(range(nFace))-set(ifaces))\n",
    "    \n",
    "    for iface in ifaces:\n",
    "        iSamePerson = list(ifaces)\n",
    "        \n",
    "        #find negative faces\n",
    "        nNegativeFaces = (FaceEmbedding_Dist[iface,iOtherPerson]<dist_threshold).sum()\n",
    "        nNegativeFaces = max(1,nNegativeFaces)\n",
    "        if nNegativeFaces == 0:\n",
    "            continue\n",
    "        \n",
    "        iNegativeFaces = FaceEmbedding_Dist[iface,iOtherPerson].argsort()[:nNegativeFaces]\n",
    "        iNegativeFaces = np.array(iOtherPerson)[iNegativeFaces]\n",
    "        \n",
    "        DistNegativeFaces = FaceEmbedding_Dist[iface,list(iNegativeFaces)]\n",
    "        probNegativeFaces = DistNegativeFaces.max() - DistNegativeFaces + 0.1\n",
    "        probNegativeFaces = probNegativeFaces/probNegativeFaces.sum()\n",
    "        \n",
    "        #find positive faces\n",
    "        nPositiveFaces = (FaceEmbedding_Dist[iface,iSamePerson]>dist_threshold).sum()\n",
    "        nPositiveFaces = max(1,nPositiveFaces)\n",
    "        \n",
    "        iPositiveFaces = FaceEmbedding_Dist[iface,iSamePerson].argsort()[-nPositiveFaces:]\n",
    "        iPositiveFaces = np.array(iSamePerson)[iPositiveFaces]\n",
    "        \n",
    "        DistPositiveFaces = FaceEmbedding_Dist[iface,list(iPositiveFaces)]\n",
    "        probPositiveFaces = DistPositiveFaces.max() - DistPositiveFaces + 0.1\n",
    "        probPositiveFaces = probPositiveFaces/probPositiveFaces.sum()\n",
    "        \n",
    "        #samples\n",
    "        nTotalSample = nNegativeFaces*nPositiveFaces+1\n",
    "        \n",
    "        iNegative = np.random.choice(nNegativeFaces,nTotalSample, p = probNegativeFaces)\n",
    "        iNegative = iNegativeFaces[iNegative]\n",
    "        iPositive = np.random.choice(nPositiveFaces,nTotalSample, p = probPositiveFaces)\n",
    "        iPositive = iPositiveFaces[iPositive]\n",
    "\n",
    "        iAnchor = np.ones((nTotalSample,),dtype=int)*iface\n",
    "    \n",
    "        A += list(iAnchor)\n",
    "        P += list(iPositive)\n",
    "        N += list(iNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAPN = len(A)\n",
    "print('%d number of A, P, N combinations had been identified' % nAPN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAPN = len(A)\n",
    "print('%d number of A, P, N combinations had been identified' % nAPN)\n",
    "APN, AP, AN = [], [] ,[]\n",
    "for i, iA in enumerate(A):\n",
    "    iP, iN = P[i], N[i]\n",
    "    Dist_AP = FaceEmbedding_Dist[iA,iP]\n",
    "    Dist_AN = FaceEmbedding_Dist[iA,iN]\n",
    "    APN.append(Dist_AP-Dist_AN)\n",
    "    AP.append(Dist_AP)\n",
    "    AN.append(Dist_AN)\n",
    "\n",
    "plt.hist(APN,bins=20,label='AP-AN')\n",
    "plt.hist(AP, bins=20,label='AP')\n",
    "plt.hist(AN, bins=20,label='AN')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('APN = %1.3f +\\- %1.3f' % (np.array(APN).mean(), np.array(APN).std()))\n",
    "print('AP = %1.3f +\\- %1.3f' % (np.array(AP).mean(), np.array(AP).std()))\n",
    "print('AN = %1.3f +\\- %1.3f' % (np.array(AN).mean(), np.array(AN).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SiameseModel.fit([FaceData[A[:5]],FaceData[P[:5]],FaceData[N[:5]]], np.ones((5,)), epochs = 1, batch_size = 32)\n",
    "SiameseModel.fit([FaceData[A],FaceData[P],FaceData[N]], np.zeros((nAPN,)), epochs = 1, batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time FaceEmbedding = FNModel.predict(FaceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components = 2)\n",
    "x_std = StandardScaler().fit_transform(FaceEmbedding)\n",
    "x_feature_pca = pca.fit_transform(x_std)\n",
    "plt.scatter(x_feature_pca[:,0],x_feature_pca[:,1],c=labels,cmap='jet')\n",
    "plt.title('feature space')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "Note that points are more clustered based on color. This means that the model now can seperate different faces better than before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCorrect = 0\n",
    "for i in test_idx:\n",
    "    p = distance_based_prediction(FaceEmbedding[train_idx], labels[train_idx], FaceEmbedding[i])\n",
    "    if p == labels[i]:\n",
    "        nCorrect += 1\n",
    "print('Face recognition accuracy using purely distance based method: %3.3f %%' % (100.*(0.+nCorrect)/len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distances_within_class = []\n",
    "Distances_among_class = []\n",
    "\n",
    "FaceEmbedding_Dist = np.ones((nFace,nFace))*100\n",
    "for i in range(nFace):\n",
    "    for j in range(i,nFace):\n",
    "        FaceEmbedding_Dist[i,j]=face_dist(FaceEmbedding[i,:],FaceEmbedding[j,:])\n",
    "        FaceEmbedding_Dist[j,i]=FaceEmbedding_Dist[i,j]\n",
    "        if labels[i]==labels[j]:\n",
    "            Distances_within_class.append(FaceEmbedding_Dist[i,j])\n",
    "        else:\n",
    "            Distances_among_class.append(FaceEmbedding_Dist[i,j])\n",
    "            \n",
    "Distances_within_class = np.array(Distances_within_class)\n",
    "Distances_among_class = np.array(Distances_among_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(FaceEmbedding_Dist,cmap='jet')\n",
    "plt.title('Distance matrix')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "_ = plt.hist(Distances_among_class,bins = 50, label = 'cross class',normed = True)\n",
    "_ = plt.hist(Distances_within_class,bins = 50, label = 'same class', normed = True)\n",
    "plt.title('Distribution of cross-class distance')\n",
    "plt.legend()\n",
    "\n",
    "print('Cross-class distance = %1.3f +\\- %1.3f' % (Distances_among_class.mean(), Distances_among_class.std()))\n",
    "print('Same-class distance = %1.3f +\\- %1.3f' % (Distances_within_class.mean(), Distances_within_class.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note\n",
    "After only 1 epoch of training on Siamese model, the prediction accuracy based on embedding distance has increased from 74.1% to 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNModel.save('./FaceNetModel/FaceNetModel_epoc1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find hard to train positive and negative combinations\n",
    "A = []\n",
    "P = []\n",
    "N = []\n",
    "\n",
    "dist_threshold_diff = 0.4\n",
    "dist_threshold_same = 0.3\n",
    "for i in range(nPeople):\n",
    "    ifaces = np.where(labels==i)[0]\n",
    "\n",
    "    iOtherPerson = list(set(range(nFace))-set(ifaces))\n",
    "    \n",
    "    for iface in ifaces:\n",
    "        iSamePerson = list(ifaces)\n",
    "        \n",
    "        #find negative faces\n",
    "        nNegativeFaces = (FaceEmbedding_Dist[iface,iOtherPerson]<dist_threshold_diff).sum()\n",
    "        nNegativeFaces = max(1,nNegativeFaces)\n",
    "        if nNegativeFaces == 0:\n",
    "            continue\n",
    "        \n",
    "        iNegativeFaces = FaceEmbedding_Dist[iface,iOtherPerson].argsort()[:nNegativeFaces]\n",
    "        iNegativeFaces = np.array(iOtherPerson)[iNegativeFaces]\n",
    "        \n",
    "        DistNegativeFaces = FaceEmbedding_Dist[iface,list(iNegativeFaces)]\n",
    "        probNegativeFaces = DistNegativeFaces.max() - DistNegativeFaces + 0.1\n",
    "        probNegativeFaces = probNegativeFaces/probNegativeFaces.sum()\n",
    "        \n",
    "        #find positive faces\n",
    "        nPositiveFaces = (FaceEmbedding_Dist[iface,iSamePerson]>dist_threshold_same).sum()\n",
    "        nPositiveFaces = max(1,nPositiveFaces)\n",
    "        \n",
    "        iPositiveFaces = FaceEmbedding_Dist[iface,iSamePerson].argsort()[-nPositiveFaces:]\n",
    "        iPositiveFaces = np.array(iSamePerson)[iPositiveFaces]\n",
    "        \n",
    "        DistPositiveFaces = FaceEmbedding_Dist[iface,list(iPositiveFaces)]\n",
    "        probPositiveFaces = DistPositiveFaces.max() - DistPositiveFaces + 0.1\n",
    "        probPositiveFaces = probPositiveFaces/probPositiveFaces.sum()\n",
    "        \n",
    "        #samples\n",
    "        nTotalSample = nNegativeFaces*nPositiveFaces+1\n",
    "        \n",
    "        iNegative = np.random.choice(nNegativeFaces,nTotalSample, p = probNegativeFaces)\n",
    "        iNegative = iNegativeFaces[iNegative]\n",
    "        iPositive = np.random.choice(nPositiveFaces,nTotalSample, p = probPositiveFaces)\n",
    "        iPositive = iPositiveFaces[iPositive]\n",
    "\n",
    "        iAnchor = np.ones((nTotalSample,),dtype=int)*iface\n",
    "    \n",
    "        A += list(iAnchor)\n",
    "        P += list(iPositive)\n",
    "        N += list(iNegative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nAPN = len(A)\n",
    "print('%d number of A, P, N combinations had been identified' % nAPN)\n",
    "APN, AP, AN = [], [] ,[]\n",
    "for i, iA in enumerate(A):\n",
    "    iP, iN = P[i], N[i]\n",
    "    Dist_AP = FaceEmbedding_Dist[iA,iP]\n",
    "    Dist_AN = FaceEmbedding_Dist[iA,iN]\n",
    "    APN.append(Dist_AP-Dist_AN)\n",
    "    AP.append(Dist_AP)\n",
    "    AN.append(Dist_AN)\n",
    "\n",
    "plt.hist(APN,bins=20,label='AP-AN')\n",
    "plt.hist(AP, bins=20,label='AP')\n",
    "plt.hist(AN, bins=20,label='AN')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('APN = %1.3f +\\- %1.3f' % (np.array(APN).mean(), np.array(APN).std()))\n",
    "print('AP = %1.3f +\\- %1.3f' % (np.array(AP).mean(), np.array(AP).std()))\n",
    "print('AN = %1.3f +\\- %1.3f' % (np.array(AN).mean(), np.array(AN).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SiameseModel.fit([FaceData[A],FaceData[P],FaceData[N]], np.zeros((nAPN,)), epochs = 1, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FaceEmbedding = FNModel.predict(FaceData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = decomposition.PCA(n_components = 2)\n",
    "x_std = StandardScaler().fit_transform(FaceEmbedding)\n",
    "x_feature_pca = pca.fit_transform(x_std)\n",
    "plt.scatter(x_feature_pca[:,0],x_feature_pca[:,1],c=labels)\n",
    "plt.title('feature space')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCorrect = 0\n",
    "for i in test_idx:\n",
    "    p = distance_based_prediction(FaceEmbedding[train_idx], labels[train_idx], FaceEmbedding[i])\n",
    "    if p == labels[i]:\n",
    "        nCorrect += 1\n",
    "print('Face recognition accuracy using purely distance based method: %3.3f %%' % (100.*(0.+nCorrect)/len(test_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Distances_within_class = []\n",
    "Distances_among_class = []\n",
    "\n",
    "FaceEmbedding_Dist = np.ones((nFace,nFace))*100\n",
    "for i in range(nFace):\n",
    "    for j in range(i,nFace):\n",
    "        FaceEmbedding_Dist[i,j]=face_dist(FaceEmbedding[i,:],FaceEmbedding[j,:])\n",
    "        FaceEmbedding_Dist[j,i]=FaceEmbedding_Dist[i,j]\n",
    "        if labels[i]==labels[j]:\n",
    "            Distances_within_class.append(FaceEmbedding_Dist[i,j])\n",
    "        else:\n",
    "            Distances_among_class.append(FaceEmbedding_Dist[i,j])\n",
    "            \n",
    "Distances_within_class = np.array(Distances_within_class)\n",
    "Distances_among_class = np.array(Distances_among_class)\n",
    "\n",
    "plt.imshow(FaceEmbedding_Dist,cmap='jet')\n",
    "plt.title('Distance matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.figure()\n",
    "_ = plt.hist(Distances_among_class,bins = 50, label = 'cross class',normed = True)\n",
    "_ = plt.hist(Distances_within_class,bins = 50, label = 'same class', normed = True)\n",
    "plt.title('Distribution of cross-class distance')\n",
    "plt.legend()\n",
    "\n",
    "print('Cross-class distance = %1.3f +\\- %1.3f' % (Distances_among_class.mean(), Distances_among_class.std()))\n",
    "print('Same-class distance = %1.3f +\\- %1.3f' % (Distances_within_class.mean(), Distances_within_class.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FNModel.save('./FaceNetModel/FaceNetModel_epoc3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
